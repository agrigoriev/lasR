[{"path":"/articles/baba.html","id":"concept","dir":"Articles","previous_headings":"","what":"Concept","title":"Buffered Area Based Approach","text":"area-based approach partitions study area cells computes derived metrics points lie within cell. method offers straightforward means map value interest across territory. However, one drawback mapping resolution typically coarse, cells typically measuring 20 x 20 meters, corresponding 400 square meters inventory plots used build predictive model. Achieving finer resolution possible. lasR, introduced concept Buffered Area Based Approach (BABA) Moving Windows Area Based Approach (MWABA). BABA, metrics computed using points within cell size s (typically 20 meters), akin classical ABA. However, resolution raster effectively r due moving window progresses steps size r. instance, can compute average Z elevation 400 square meter area resolution 5 meters, instead typical 20 meters.","code":""},{"path":"/articles/baba.html","id":"exemple-1","dir":"Articles","previous_headings":"","what":"Exemple 1","title":"Buffered Area Based Approach","text":"’s important emphasize BABA, although resolution set 5 meters, values pixel computed based 20-meter cell. metric remains valid concerning reference plot inventory, typically 400 square meters. Consequently, becomes feasible predict map values interest fine-grained resolution using regular plot inventory data.","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") aba  = rasterize(20, \"zmean\")      # ABA baba = rasterize(c(5,20), \"zmean\") # BABA pipeline = aba + baba ans = exec(pipeline, on = f)  terra::plot(ans[[1]], col = col, main = \"ABA\") terra::plot(ans[[2]], col = col, main = \"BABA\")"},{"path":"/articles/baba.html","id":"exemple-2","dir":"Articles","previous_headings":"","what":"Exemple 2","title":"Buffered Area Based Approach","text":"approach also enables mapping point density finer resolution, among possibilities.","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") c1 <- rasterize(1, \"count\") c2  <- rasterize(c(1,4), \"count\") pipeline = c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/4, col = gray.colors(15,0,1), main = \"Regular\")   # divide by 4 to get the density terra::plot(res[[2]]/25, col = gray.colors(15,0,1), main = \"Moving windows\")  # divide by 25 to get the density"},{"path":"/articles/baba.html","id":"naming-convention","dir":"Articles","previous_headings":"","what":"Naming convention","title":"Buffered Area Based Approach","text":"Buffered Area Based Approach (BABA), Moving Windows Area Based Approach (MWABA), Multi-Resolution Area Based Approach (MRABA) – feel free refer however prefer.","code":""},{"path":"/articles/lasR1.html","id":"rationnale-for-lasr-vs--lidr","dir":"Articles","previous_headings":"","what":"Rationnale for lasR vs. lidR","title":"1. Why lasR?","text":"need new package? short answer lies following graph. x-axis represents time perform three different rasterizations (CHM, DTM, density map), y-axis represents amount RAM memory used lidR lasR (details benchmark vignette). lasR intended much efficient lidR terms memory usage computation times.  second issue absence powerful pipeline engine lidR. Performing task simple extracting deriving metrics multiple inventory plots non-normalized collection files easy lidR. straightforward point cloud normalized, , users must write complex custom script. introduction real pipelines, lasR enables users complex tasks easier way (see tutorial vignette well pipeline vignette). Last least, almost decade additional experience R, C++, point cloud processing, lot feedback compared started creation lidR. simply technically capable writing lasR ten years ago!","code":""},{"path":[]},{"path":"/articles/lasR1.html","id":"pipeline","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Pipeline","title":"1. Why lasR?","text":"lasR introduces versatile pipeline engine, enabling creation complex processing pipelines. Users can simultaneously create ABA compute DTM one read pass, leading significant speed-.","code":""},{"path":"/articles/lasR1.html","id":"data-loading","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Data loading","title":"1. Why lasR?","text":"Unlike lidR, lasR load lidar data data.frame. designed efficient data processing, memory management C++ level. Consequently, read_las() function. Everything internally efficiently stored C++ structure keeps data compact memory. However, entry points available inject user-defined R code C++ pipeline.","code":""},{"path":"/articles/lasR1.html","id":"dependencies","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Dependencies","title":"1. Why lasR?","text":"lasR 0 dependency. doesn’t even depend Rcpp. lasR use terra sf R level reading writing spatial data; instead, links GDAL. terra sf installed, output files read packages. Due absence dependency R package non-loading data R objects, also dependency rgl, resulting interactive 3D viewer like lidR.","code":""},{"path":"/articles/lasR1.html","id":"code","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Code","title":"1. Why lasR?","text":"lasR written 100% C++ contains R code. utilizes source code lidR significant improvements. major improvements observed benchmark much source code rather organization code, .e., longer using data.frame, memory management C++ rather R, processing R level, pipelines, .","code":""},{"path":"/articles/lasR1.html","id":"should-i-use-lidr-or-lasr","dir":"Articles","previous_headings":"","what":"Should I use lidR or lasR?","title":"1. Why lasR?","text":"question actually pretty simple answer. want explore, manipulate, test, try, retry, implement new ideas mind, use lidR. know want, want relatively common (raster metrics, DTM, CHM, tree location), especially want large coverage, use lasR.","code":""},{"path":"/articles/lasR1.html","id":"example-1","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 1","title":"1. Why lasR?","text":"received 500 km² data, want CHM DTM. → Use lasR compute fast possible.","code":""},{"path":"/articles/lasR1.html","id":"example-2","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 2","title":"1. Why lasR?","text":"want segment trees, explore different methods, test different parameters small plots. Maybe integrate custom step, ’s exploratory process. → Use lidR.","code":""},{"path":"/articles/lasR1.html","id":"example-3","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 3","title":"1. Why lasR?","text":"want extract circular ground inventories compute metrics plot. → dataset already normalized, can use either lasR lidR; pretty much equivalent. lidR easier use; lasR little bit efficient difficult use (yet pipeline vignette contains copy-pastable code ). dataset normalized, lasR much simpler case, thanks pipeline processor allows adding normalization stage computing metrics.","code":""},{"path":"/articles/lasR1.html","id":"example-4","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 4","title":"1. Why lasR?","text":"want create complex pipeline computes local shape points classify roofs wires point cloud. using shapefile, want classify water point cloud. finish, want write new classified LAS files. → Use lidR. lasR many tools. lasR lidR; much efficient less versatile fewer tools.","code":""},{"path":"/articles/lasR1.html","id":"example-5","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 5","title":"1. Why lasR?","text":"want find segment trees common algorithm. Nothing fancy. want 100 km² . → Use lasR. lidR probably fail .","code":""},{"path":"/articles/lasR2.html","id":"overall-functionality","dir":"Articles","previous_headings":"","what":"Overall functionality","title":"2. Tutorial","text":"lasR, R functions provided user designed process data directly; instead, used create pipeline. pipeline consists stages applied point cloud order. stage can either transform point cloud within pipeline without generating output process point cloud produce output. figure , 4 LAS/LAZ files pipeline (1) reads file, (2) builds writes DTM disk, (3) transforms point cloud normalizing elevation, (4) builds canopy height model using transformed point cloud, (5) transforms point cloud removing points 5 m. resulting version point cloud (points 5m) discarded lost additional stage pipeline. However, stages can added, application predictive model points 5 m stage writes point cloud disk. first file completes entire pipeline, second file used, pipeline applied fill missing parts geospatial rasters vectors produced pipeline. file loaded buffer neighboring files needed. pipeline created R interface nothing initially. building pipeline, users must call exec() function initiate computation.","code":""},{"path":"/articles/lasR2.html","id":"reader","dir":"Articles","previous_headings":"","what":"Reader","title":"2. Tutorial","text":"reader_las() stage MUST first stage pipeline (blue figure ). takes input list files process. creating pipeline stage, header files read, computation actually applied. points even read stage pipeline require read points. result returned. practice using read_las() without argument can omitted, function exec adds --fly.","code":"pipeline = reader_las() exec(pipeline, on = f) #> NULL"},{"path":"/articles/lasR2.html","id":"triangulate","dir":"Articles","previous_headings":"","what":"Triangulate","title":"2. Tutorial","text":"first stage can try triangulate(). algorithm performs Delaunay triangulation points interest. Triangulating points useful task employed numerous processing tasks. Triangulating points interesting, usually want use filter argument triangulate specific points interest. following example, triangulate points classified 2 (.e., ground). produces meshed Digital Terrain Model. example, files read sequentially, points loaded one one stored build Delaunay triangulation. lasR, one file stored memory time. program stores point cloud Delaunay triangulation current processing file. data discarded load new file. users provide path output file store result, result lost. following pipeline, building triangulation ground points, get output everything lost. following pipeline triangulation stored geopackage file providing argument ofile:  can also triangulate first returns. produce meshed Digital Surface Model. can also perform triangulations pipeline. idea lasR execute tasks one pass using pipeline: Using triangulate() without stage pipeline usually useful. Typically, triangulate() employed without ofile argument intermediate step. instance, can used rasterize().","code":"pipeline = reader_las() + triangulate(filter = keep_ground()) ans = exec(pipeline, on = f) ans #> NULL pipeline = reader_las() + triangulate(filter = keep_ground(), ofile = tempgpkg()) ans = exec(pipeline, on = f) ans #> Simple feature collection with 1 feature and 0 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: 273357.2 ymin: 5274357 xmax: 273642.9 ymax: 5274643 #> z_range:       zmin: 788.9932 zmax: 814.8322 #> Projected CRS: NAD83(CSRS) / MTM zone 7 #> # A tibble: 1 × 1 #>                                                                             geom #>                                                               <MULTIPOLYGON [m]> #> 1 Z (((273500.4 5274501 808.4787, 273501.2 5274502 808.1748, 273500.4 5274502 8…  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5) read = reader_las() del = triangulate(filter = keep_first(), ofile = tempgpkg()) ans = exec(read+del, on = f) read = reader_las() del1 = triangulate(filter = keep_ground(), ofile = tempfile(fileext = \".gpkg\")) del2 = triangulate(filter = keep_first(), ofile = tempfile(fileext = \".gpkg\")) pipeline = read + del1 + del2 ans = exec(pipeline, on = f)"},{"path":"/articles/lasR2.html","id":"rasterize","dir":"Articles","previous_headings":"","what":"Rasterize","title":"2. Tutorial","text":"rasterize() exactly users may expect even . three variations: Rasterize predefined operators. operators optimized internally, making operations fast possible, number registered operators finite. Rasterize injecting user-defined R expression. equivalent pixel_metrics() package lidR. user-defined function can mapped, making extremely versatile slower. Rasterize Delaunay triangulation. variations, users can build CHM, DTM, predictive model, anything else.","code":""},{"path":"/articles/lasR2.html","id":"rasterize---triangulation","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - triangulation","title":"2. Tutorial","text":"Let’s build DTM using triangulation ground points rasterize() stage. following pipeline, LAS files read, points loaded LAS file buffer, Delaunay triangulation ground points built, triangulation interpolated rasterized. default, rasterize() writes raster temporary file, result discarded. , exec() returns one SpatRaster triangulate() returns nothing (NULL). Therefore, pipeline contains two stages, one returns something.  Notice , contrary lidR package, usually high-level function names like rasterize_terrain(). Instead, lasR made low-level functions versatile also challenging use.","code":"# omitting reader_las() for the example del = triangulate(filter = keep_ground()) dtm = rasterize(1, del) pipeline = del + dtm ans = exec(pipeline, on = f) ans #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file226554caf38.tif  #> name        : file226554caf38 terra::plot(ans, col = gray.colors(25,0,1), mar = c(1, 1, 1, 3))"},{"path":"/articles/lasR2.html","id":"rasterize---internal-metrics","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - internal metrics","title":"2. Tutorial","text":"Let’s build two CHMs: one based highest point per pixel resolution 2 meters, second based triangulation first returns resolution 50 cm. following pipeline, using two variations rasterize(): one capable rasterizing triangulation capable rasterizing point cloud predefined operator (max). output named list two SpatRaster.  simplicity package pre-installed pipelines named chm() dtm() explained .","code":"del <- triangulate(filter = keep_first()) chm1 <- rasterize(2, \"max\") chm2 <- rasterize(0.5, del) pipeline <- del + chm1 + chm2 ans <- exec(pipeline, on = f)  terra::plot(ans[[1]], mar = c(1, 1, 1, 3), col = col) terra::plot(ans[[2]], mar = c(1, 1, 1, 3), col = col)"},{"path":"/articles/lasR2.html","id":"rasterize---custom-metrics","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - custom metrics","title":"2. Tutorial","text":"Last least, let’s compute map median intensity injecting user-defined expression. Like lidR, attributes point cloud named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. users familiar lidR package, note ScanAngleRank/ScanAngle; instead scanner angle always named ScanAngle numeric. Also flags named Withheld, Synthetic Keypoint.  Notice , specific case, using rasterize(10, \"imean\") efficient.","code":"pipeline = rasterize(10, median(Intensity)) ans = exec(pipeline, on = f)  terra::plot(ans, mar = c(1, 1, 1, 3), col = heat.colors(15))"},{"path":"/articles/lasR2.html","id":"rasterize---buffered","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - buffered","title":"2. Tutorial","text":"lasR package introduced concept buffered area-based approach enhance resolution prediction maps. However, concept covered detail tutorial. information, readers can refer dedicated article","code":""},{"path":"/articles/lasR2.html","id":"transform-with","dir":"Articles","previous_headings":"","what":"Transform with","title":"2. Tutorial","text":"Another way use Delaunay triangulation transform point cloud. Users can add subtract triangulation point cloud, effectively normalizing . Unlike lidR package, high-level function names like normalize_points(). Instead, lasR composed low-level functions offer versatility. Let’s normalize point cloud using triangulation ground points (meshed DTM). following example, triangulation used transform_with() modifies point cloud pipeline. triangulate() transform_with() return nothing. output NULL. convenience pipeline pre-recorded package name normalize(). transform_with() can also transform raster. presented tutorial. obtain meaningful output, necessary chain another stage. point cloud modified , discarded nothing . instance, can compute Canopy Height Model (CHM) normalized point cloud. following pipeline, first rasterization (chm1) applied normalization, second rasterization occurs transform_with(), thus applied transformed point cloud.  performing normalization, users may want write normalized point cloud disk later use. case, can append write_las() stage pipeline.","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline = del + norm ans = exec(pipeline, on = f) ans #> NULL del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") chm1 = rasterize(2, \"max\") chm2 = rasterize(2, \"max\") pipeline = chm1 + del + norm + chm2 ans = exec(pipeline, on = f)  col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(15) terra::plot(c(ans[[1]], ans[[2]]), col = col)"},{"path":"/articles/lasR2.html","id":"write-las","dir":"Articles","previous_headings":"","what":"Write LAS","title":"2. Tutorial","text":"write_las() can called point pipeline. writes one file per input file, using name input files added prefixes suffixes. following pipeline, read files, write ground points files named original files suffix _ground, perform triangulation entire point cloud, followed normalization. Finally, write normalized point cloud suffix _normalized. crucial include wildcard * file path; otherwise, single large file created. behavior may intentional. Let’s consider creating file merge pipeline. following example, wildcard * used names LAS/LAZ files. input files read, points sequentially written single file dataset_merged.laz, naturally forming merge pipeline.","code":"write1 = write_las(paste0(tempdir(), \"/*_ground.laz\"), filter = keep_ground()) write2 = write_las(paste0(tempdir(), \"/*_normalized.laz\"), ) del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline =  write1 + del + norm + write2 ans = exec(pipeline, on = f) ans #>  - write_las : /tmp/RtmplpNxon/bcts_1_ground.laz /tmp/RtmplpNxon/bcts_2_ground.laz  #>  - write_las : /tmp/RtmplpNxon/bcts_1_normalized.laz /tmp/RtmplpNxon/bcts_2_normalized.laz ofile = paste0(tempdir(), \"/dataset_merged.laz\") merge = reader_las() + write_las(ofile) ans = exec(merge, on = f) ans #> [1] \"/tmp/RtmplpNxon/dataset_merged.laz\""},{"path":"/articles/lasR2.html","id":"callback","dir":"Articles","previous_headings":"","what":"Callback","title":"2. Tutorial","text":"callback stage holds significant importance second last entry point inject R code pipeline, following rasterize(). familiar lidR package, initial step often involves reading data lidR::readLAS() expose point cloud data.frame object R. contrast, lasR loads point cloud optimally C++ without exposing directly R. However, callback, becomes possible expose point cloud data.frame executing specific R functions. Similar lidR, attributes point cloud lasR named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. Notably, users accustomed lidR package, scanner angle consistently named ScanAngle numeric, opposed ScanAngleRank/ScanAngle. Additionally, flags named Withheld, Synthetic, Keypoint. Let’s delve simple example. LAS file, callback loads point cloud data.frame invokes meanz() function data.frame. output list two elements processed two files (f displayed document). average Z elevation respectively 809.08 13.27 file. mindful , given LAS/LAZ file, point cloud may contain points original file file loaded buffer. clarification matter provided later. callback function versatile can also employed edit point cloud. user-defined function returns data.frame number rows original one, function edits underlying C++ dataset. enables users perform tasks assigning class specific point. physically removing points possible, users can flag points Withheld. cases, points processed subsequent stages, discarded. observed, , time callback explicitly return anything; however, edited point cloud internally. generate output, users must use another stage write_las(). ’s important note write_las() write point number 12 flagged withheld. Neither subsequent stage process . point still memory discarded. memory efficiency reasons, possible physically remove point underlying memory lasR. Instead, points flagged withheld never processed. One consequence , points flagged withheld LAS/LAZ file processed lasR. aligns intended purpose flag according LAS specification may differ default behavior many software market including lidR. Now, let’s explore capabilities callback . First, let’s create lidR-like read_las() function expose point cloud R. following example, user-defined function employed return data.frame . user’s function returns data.frame number points original dataset, updates points C++ level. , use no_las_update = TRUE explicitly return result. Ground points can also classified using R function, one provided RCSF package: callback() exposes point cloud data.frame. way expose point clouds users manageable way. One reasons lasR memory-efficient faster lidR expose point cloud data.frame. Thus, pipelines using callback() significantly different lidR. advantage using lasR ability pipe different stages.","code":"meanz = function(data){ return(mean(data$Z)) } call = callback(meanz, expose = \"xyz\") ans = exec(call, on = f) print(ans) #>  - 809.0835  #>  - 13.27202 edit_points = function(data) {   data$Classification[5:7] = c(2L,2L,2L)   data$Withheld = FALSE   data$Withheld[12] = TRUE   return(data) }  call = callback(edit_points, expose = \"xyzc\") ans = exec(call, on = f) ans #> NULL read_las = function(f, select = \"xyzi\", filter = \"\") {   load = function(data) { return(data) }   read = reader_las(filter = filter)   call = callback(load, expose = select, no_las_update = TRUE)   return (exec(read+call, on = f)) }  f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") las = read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123 csf = function(data) {   id = RCSF::CSF(data)   class = integer(nrow(data))   class[id] = 2L   data$Classification <- class   return(data) }  read = reader_las() classify = callback(csf, expose = \"xyz\") write = write_las() pipeline = read + classify + write exec(pipeline, on = f)"},{"path":"/articles/lasR2.html","id":"local-maximum","dir":"Articles","previous_headings":"","what":"Local maximum","title":"2. Tutorial","text":"stage works either point cloud raster. following pipeline first stage builds CHM, second stage finds local maxima point cloud second stages finds local maxima chm. lm1 lm2 expected produce relatively close results strictly identical.","code":"chm = rasterize(1, \"max\") lm1 = local_maximum(3) lm2 = local_maximum_raster(chm, 3) pipeline = chm + lm1 + lm2"},{"path":"/articles/lasR2.html","id":"tree-segmentation","dir":"Articles","previous_headings":"","what":"Tree Segmentation","title":"2. Tutorial","text":"section presents complex pipeline tree segmentation using local_maximum_raster() identify tree tops CHM. uses region_growing() segment trees using seeds produced local_maximum_raster(). Canopy Height Model (CHM) triangulation-based using triangulation() rasterize() first returns. CHM post-processed pit_fill(), algorithm designed enhance CHM filling pits NAs. reader may noticed seeds produced raster one used region_growing(). checked internally ensure seeds matching raster used segmenting trees. tutorial, pipeline tested one file render page faster. However, pipeline can applied number files produce continuous output, managing buffer files. Every intermediate output can exported, tutorial, export everything display outputs.","code":"del = triangulate(filter = keep_first()) chm = rasterize(0.5, del) chm2 = pit_fill(chm) seed = local_maximum_raster(chm2, 3) tree = region_growing(chm2, seed) pipeline = del + chm + chm2 +  seed + tree ans = exec(pipeline, on = f) col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(25) col2 = grDevices::colorRampPalette(c(\"purple\", \"blue\", \"cyan2\", \"yellow\", \"red\", \"green\"))(50) terra::plot(ans$rasterize, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$pit_fill, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$region_growing, col = col2[sample.int(50, 277, TRUE)], mar = c(1, 1, 1, 3)) plot(ans$local_maximum$geom, add = T, pch = 19, cex = 0.5)"},{"path":"/articles/lasR2.html","id":"buffer","dir":"Articles","previous_headings":"","what":"Buffer","title":"2. Tutorial","text":"Point clouds typically stored multiple contiguous files. avoid edge artifacts, file must loaded extra points coming neighboring files. Everything handled automatically, except callback() stage. callback(), point cloud exposed data.frame buffer, providing user-defined function spatial context. callback used edit points, everything handled internally. However, R object returned, responsibility user handle buffer. example, following pipeline, processing two files, callback() used count number points. presence triangulate() implies file loaded buffer make valid triangulation. Consequently, counting points callback() returns points summarise() summarise() internal function knows deal buffer. can compare pipeline without triangulate(). case, reason use buffer, files buffered. counts equal. handle buffer, user can read attribute bbox data.frame. contains bounding box point cloud without buffer use column Buffer contains TRUE FALSE point. TRUE, point buffer. buffer exposed user includes letter 'b'. conclusion, hypothesis user-defined function returns something complex, two ways handle buffer: either using bounding box using Buffer flag. third option use drop_buffer. case users ensure receive data.frame include points buffer.","code":"count = function(data) { length(data$X) } del = triangulate(filter = keep_ground()) npts = callback(count, expose = \"x\") sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - 682031  #>  - 931581 ans$callback[[1]]+ ans$callback[[2]] #> [1] 1613612 ans$summary$npoints #> [1] 1355607 ans = exec(npts + sum, on = f) ans$callback[[1]]+ ans$callback[[2]] #> [1] 1355607 ans$summary$npoints #> [1] 1355607 count_buffer_aware = function(data) {   bbox = attr(data, \"bbox\")   npoints = sum(!data$Buffer)   return(list(bbox = bbox, npoints = npoints)) }  del = triangulate(filter = keep_ground()) npts = callback(count_buffer_aware, expose = \"b\") # b for buffer sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - List: #>    - bbox : 885022.4 629157.2 885210.2 629400  #>    - npoints : 531662  #>  - List: #>    - bbox : 885024.1 629400 885217.1 629700  #>    - npoints : 823945 ans$callback[[1]]$npoints+ ans$callback[[2]]$npoints #> [1] 1355607 ans$summary$npoints #> [1] 1355607"},{"path":"/articles/lasR2.html","id":"hulls","dir":"Articles","previous_headings":"","what":"Hulls","title":"2. Tutorial","text":"Delaunay triangulation defines convex polygon, represents convex hull points. However, dense point clouds, removing triangles large edges due absence points results complex structure.  hulls() algorithm computes contour mesh, producing concave hull holes:  However hulls() likely used without triangulation. case returns bounding box LAS/LAZ file read header. used triangulate(0) returns convex hull inefficient way get convex hull.","code":"del = triangulate(15, filter = keep_ground(), ofile = tempgpkg()) ans = exec(del, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5) del = triangulate(15, filter = keep_ground()) bound = hulls(del) ans = exec(del+bound, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5, col = \"gray\")"},{"path":"/articles/lasR2.html","id":"sampling-voxel","dir":"Articles","previous_headings":"","what":"Sampling Voxel","title":"2. Tutorial","text":"sampling_voxel() summarise() functions operate similarly algorithms, output depends position pipeline:","code":"pipeline = summarise() + sampling_voxel(4) + summarise() ans = exec(pipeline, on = f) print(head(ans[[1]])) #>  - npoints : 73403  #>  - nsingle : 31294  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 53538 15828 3569 451 16 1  #>  - npoints_per_class : 61347 8159 3897 print(head(ans[[2]])) #>  - npoints : 12745  #>  - nsingle : 5019  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 9423 2600 623 92 7  #>  - npoints_per_class : 10852 1524 369"},{"path":"/articles/lasR2.html","id":"readers","dir":"Articles","previous_headings":"","what":"Readers","title":"2. Tutorial","text":"reader_las() MUST first stage pipeline even can conveniently omitted simplest form. However several readers hidden behind reader_las(): reader_las_coverage(): read files process entire point cloud. default behavior reader_las(). reader_las_rectangles(): read rectangular regions interest coverage process sequentially. reader_las_circles(): read circular regions interest coverage process sequentially. following pipeline triangulates ground points, normalizes point cloud, computes metric interest file entire coverage. file loaded buffer triangulation performed without edge artifacts. Notice use drop_buffer = TRUE expose data.frame without buffer used perform triangulation normalization. following pipeline, contrary, works exactly operates circular plots. readers allow building ground inventory pipeline, plot extraction examples","code":"my_metric_fun = function(data) { mean(data$Z) } tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metric <- callback(my_metric_fun, expose = \"z\", drop_buffer = TRUE) pipeline = norm + metric pipeline = reader_las_circles(xcenter, ycenter, 11.28) + pipeline"},{"path":"/articles/lasR2.html","id":"plot-inventory","dir":"Articles","previous_headings":"","what":"Plot inventory","title":"2. Tutorial","text":"pipeline extracts plot inventory using shapefile non-normalized point cloud, normalizes plot, computes metrics plot, writes normalized non-normalized plot separate files. circular plot loaded buffer perform correct triangulation. plots exposed R without buffer using drop_buffer = TRUE.","code":"ofiles_plot <- paste0(tempdir(), \"/plot_*.las\") ofiles_plot_norm <- paste0(tempdir(), \"/plot_*_norm.las\")  my_metric_fun = function(data) { mean(data$Z) }  library(sf) inventory <- st_read(\"shapefile.shp\") coordinates <- st_coordinates(inventory) xcenter <- coordinates[,1] ycenter <- coordinates[,2]  read <- reader_las(xc = xcenter, yc = ycenter, r = 11.28)  tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metric <- callback(my_metric_fun, expose = \"z\", drop_buffer = TRUE) write1 <- write_las(ofiles_plot) write2 <- write_las(ofiles_plot_norm)  pipeline = read + trans + write1 + norm + write2"},{"path":"/articles/lasR2.html","id":"wildcard-usage","dir":"Articles","previous_headings":"","what":"Wildcard Usage","title":"2. Tutorial","text":"Usually, write_las() used wildcard ofile argument (see ) write one file per processed file. Otherwise, everything written single massive LAS file (might desired behavior). contrary, rasterize() used without wildcard write everything single raster file, also accepts wildcard write results multiple files, useful reader_las_circles() avoid one massive raster mostly empty. Compare pipeline without wildcard. Without wildcard, output single raster covers entire point cloud two patches populated pixels.  wildcard, output contains two rasters cover regions interest.","code":"ofile = paste0(tempdir(), \"/chm.tif\")   # no wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader_las(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) r0 = exec(pipeline, on = f)  terra::plot(r0, col = col) # covers the entire collection of files ofile = paste0(tempdir(), \"/chm_*.tif\") # wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader_las(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) ans = exec(pipeline, on = f)  r1 = terra::rast(ans[1]) r2 = terra::rast(ans[2]) terra::plot(r1, col = col) terra::plot(r2, col = col)"},{"path":"/articles/lasR2.html","id":"compatibility-with-lidr","dir":"Articles","previous_headings":"","what":"Compatibility with lidR","title":"2. Tutorial","text":"lasR depends lidR compatibility . Instead providing paths files folder possible pass LAScatalog LAS object readers. case LAScatalog, exec() respects processing options LAScatalog including chunk size, chunk buffer, progress bar display partial processing. general case, options can supplied arguments exec() functions.","code":"library(lasR) library(lidR)  pipeline = normalize() + write_las()  ctg = readLAScatalog(folder) ans = exec(pipeline, on = ctg)  las = readLAS(file) ans = exec(pipeline, on = las)"},{"path":"/articles/lasR2.html","id":"parallel-processing","dir":"Articles","previous_headings":"","what":"Parallel processing","title":"2. Tutorial","text":"topic covered dedicated article","code":""},{"path":[]},{"path":"/articles/lasR3.html","id":"normalize","dir":"Articles","previous_headings":"Pipeline factories","what":"Normalize","title":"3. Pipelines","text":"pipeline already installed package. can used way","code":"normalize = function(extrabytes = FALSE) {   tri <- triangulate(filter = keep_ground())   pipeline <- tri      if (extrabytes)   {     extra = add_extrabytes(\"int\", \"HAG\", \"Height Above Ground\")     trans = transform_with(tri, store_in_attribute = \"HAG\")     pipeline = pipeline + extra + trans   }   else   {     trans = transform_with(tri)     pipeline = pipeline + trans   }      return(pipeline) } pipeline = reader(f) + normalize() + write_las(o)"},{"path":[]},{"path":"/articles/lasR3.html","id":"with-csf","dir":"Articles","previous_headings":"Pipeline factories > Classify ground","what":"With CSF","title":"3. Pipelines","text":"","code":"ground_csf = function(smooth = FALSE, threshold = 0.5, resolution = 0.5, rigidness = 1L, iterations = 500L, step = 0.65) {   csf = function(data, smooth, threshold, resolution, rigidness, iterations, step)   {     id = RCSF::CSF(data, smooth, threshold, resolution, rigidness, iterations, step)     class = integer(nrow(data))     class[id] = 2L     data$Classification <- class     return(data)   }      classify = callback(csf, expose = \"xyz\", smooth = smooth, threshold = threshold, resolution = resolution, rigidness = rigidness, iterations = iterations, step = step)   return(classify) } pipeline = reader(f) + ground_csf() + write_las(o)"},{"path":"/articles/lasR3.html","id":"with-mcc","dir":"Articles","previous_headings":"Pipeline factories > Classify ground","what":"With MCC","title":"3. Pipelines","text":"pipelines use callback() exposes point cloud data.frame. One reasons lasR memory-efficient faster lidR expose point cloud data.frame. Thus, pipelines different classify_ground() function lidR. advantage using lasR ability pipe different stages.","code":"ground_mcc = function(s = 1.5, t = 0.3) {   csf = function(data, s, t)   {     id = RMCC::MCC(data, s, t)     class = integer(nrow(data))     class[id] = 2L     data$Classification <- class     return(data)   }      classify = callback(csf, expose = \"xyz\", s = s, t = t)   return(classify) } pipeline = reader(f) + ground_mcc() + write_las(o)"},{"path":"/articles/lasR3.html","id":"canopy-heigh-model","dir":"Articles","previous_headings":"Pipeline factories","what":"Canopy Heigh Model","title":"3. Pipelines","text":"two pipelines natively installed package name chm().","code":"chm_p2r = function(res, filter = \"\", ofile = tempfile(fileext = \".tif\")) {   return(rasterize(res, \"max\", filter = filter, ofile = ofile)) } chm_tin = function(res, ofile = tempfile(fileext = \".tif\")) {   tin = triangulate(filter = keep_first())   chm = rasterize(res, tin, ofile = ofile)   return(tin+chm) }"},{"path":"/articles/lasR3.html","id":"digital-terrain-model","dir":"Articles","previous_headings":"Pipeline factories","what":"Digital Terrain Model","title":"3. Pipelines","text":"one also natively installed package. add_class can used add class used ground 9 water.","code":"dtm = function(res, ofile = tempfile(fileext = \".tif\"), add_class = NULL) {   filter = keep_ground()   if (!is.null(add_class)) filter = filter + keep_class(add_class)   tin = triangulate(filter = filter)   chm = rasterize(res, tin, ofile = ofile)   return(tin+chm) }"},{"path":[]},{"path":"/articles/lasR3.html","id":"read-las","dir":"Articles","previous_headings":"Useful functions","what":"Read LAS","title":"3. Pipelines","text":"","code":"read_las = function(files, select = \"xyzi\", filter = \"\") {   load = function(data) { return(data) }   read = reader_las(filter = filter)   call = callback(load, expose = select, no_las_update = TRUE)   return(exec(read+call, on = f)) }"},{"path":"/articles/lasR3.html","id":"buffer-tiles","dir":"Articles","previous_headings":"Useful functions","what":"Buffer tiles","title":"3. Pipelines","text":"","code":"buffer_tiles = function(files, buffer, ofiles = paste0(tempdir(), \"/*_buffered.las\")) {   read = reader_las()   write = write_las(ofiles, keep_buffer = TRUE)   return(exec(read+write, on = files, buffer = buffer)) }"},{"path":"/articles/lasR3.html","id":"clip-circle","dir":"Articles","previous_headings":"Useful functions","what":"Clip circle","title":"3. Pipelines","text":"Writes LAS files returns data.frames. Supports sf objects input.","code":"clip_circle = function(files, geometry, radius, ofiles = paste0(tempdir(), \"/*_clipped.las\")) {   if (sf::st_geometry_type(geometry, FALSE) != \"POINT\")      stop(\"Expected POINT geometry type\")    coordinates <- sf::st_coordinates(geometry)   xcenter <- coordinates[,1]   ycenter <- coordinates[,2]      read = reader_las(xc = xcenter, yc = ycenter, r = radius)      if (length(ofiles) == 1L && ofiles == \"\")     stage = callback(function(data) { return(data) }, expose = \"*\", no_las_update = T)   else     stage = write_las(ofiles)      ans = exec(read+stage, on = files)   return(ans) }"},{"path":"/articles/lasR3.html","id":"crs","dir":"Articles","previous_headings":"Useful functions","what":"CRS","title":"3. Pipelines","text":"CRS sf object. cost applying hulls() virtually null.","code":"crs = function(files) {   pipeline = reader_las() + hulls()   ans = exec(pipeline, on = files)   return(sf::st_crs(ans)) }"},{"path":"/articles/lasR3.html","id":"inventory-metrics","dir":"Articles","previous_headings":"Useful functions","what":"Inventory metrics","title":"3. Pipelines","text":"Using sf object provide plot centers offering option normalize --fly. returns sf object extra attributes.","code":"inventory_metrics = function(files, geometry, radius, fun, normalize = FALSE) {   if (sf::st_geometry_type(geometry, FALSE) != \"POINT\")      stop(\"Expected POINT geometry type\")    coordinates <- sf::st_coordinates(geometry)   xcenter <- coordinates[,1]   ycenter <- coordinates[,2]      pipeline <- reader_las(xc = xcenter, yc = ycenter, r = radius)      if (normalize)   {     tri <- triangulate(filter = keep_ground())     trans <- transform_with(tri)     pipeline <- pipeline + tri + trans   }    pipeline <- pipeline + callback(fun, expose = \"*\")   ans <- exec(pipeline, on = files)   ans <- lapply(ans, as.data.frame)   ans <- do.call(rbind, ans)   return(cbind(geometry, ans)) }"},{"path":"/articles/lasR3.html","id":"virtual-point-cloud","dir":"Articles","previous_headings":"Useful functions","what":"Virtual point cloud","title":"3. Pipelines","text":"","code":"build_vpc = function(files, ofile) {   read = reader_las()   write = write_vpc(ofile)   exec(read+write, on = files) }"},{"path":[]},{"path":"/articles/lasR4.html","id":"code","dir":"Articles","previous_headings":"Canopy Height Model","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) chm = rasterize_canopy(ctg, 1, p2r())   # lasR set_parallel_strategy(...) pipeline = rasterize(1, \"max\") exec(pipeline, on = ctg)"},{"path":[]},{"path":[]},{"path":"/articles/lasR4.html","id":"code-1","dir":"Articles","previous_headings":"Digital Terrain Model","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) dtm = rasterize_terrain(ctg, 1, tin())  # lasR set_parallel_strategy(...) tri = triangulate() pipeline = reader_las(filter = keep_ground()) + tri + rasterize(1, tri) exec(pipeline, on = ctg)"},{"path":"/articles/lasR4.html","id":"result-1","dir":"Articles","previous_headings":"Digital Terrain Model","what":"Result","title":"4. Benchmarks of lasR vs. lidR","text":"digital terrain pipeline using exec(pipeline, ..., chunk = 1000) lasR opt_chunk_size(ctg) = 1000 lidR reduce memory usage.","code":""},{"path":"/articles/lasR4.html","id":"multiple-raster","dir":"Articles","previous_headings":"","what":"Multiple raster","title":"4. Benchmarks of lasR vs. lidR","text":"gain terms computation time much significant running multiple stages single pipeline files read lasR multiple times lidR. , operations executed single pass C++ level, resulting efficient memory management.","code":""},{"path":"/articles/lasR4.html","id":"code-2","dir":"Articles","previous_headings":"Multiple raster","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } ctg = readLAScatalog(f) chm = rasterize_canopy(ctg, 1, p2r()) met = pixel_metrics(ctg, ~custom_function(Z, Intensity), 20) den = rasterize_density(ctg, 5)  # lasR set_parallel_strategy(...) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } chm = rasterize(1, \"max\") met = rasterize(20, custom_function(Z, Intensity)) den = rasterize(5, \"count\") pipeline = chm + met + den exec(pipeline, on = folder)"},{"path":[]},{"path":[]},{"path":"/articles/lasR4.html","id":"code-3","dir":"Articles","previous_headings":"Normalization","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) opt_output_files(ctg) <- paste0(tempdir(), \"/*_norm\") norm = normalize_height(ctg, tin())  # lasR set_parallel_strategy(...) pipeline = reader(f) + normalize() + write_las() processor(pipeline)"},{"path":[]},{"path":[]},{"path":"/articles/lasR4.html","id":"code-4","dir":"Articles","previous_headings":"Local maximum","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) tree = locate_trees(ctg, lmf(5))  # lasR set_parallel_strategy(...) pipeline = reader(f) + local_maximum(5) processor(pipeline)"},{"path":[]},{"path":"/articles/lasR4.html","id":"complex-pipeline","dir":"Articles","previous_headings":"","what":"Complex Pipeline","title":"4. Benchmarks of lasR vs. lidR","text":"complex pipeline, point cloud normalized written new files. Digital Terrain Model (DTM) produced, Canopy Height Model (CHM) built, individual trees detected. detected trees used seeds region-growing algorithm segments trees. lasR pipeline can handle hundreds laser tiles, lidR may struggle apply pipeline, especially tree segmentation.","code":""},{"path":"/articles/lasR4.html","id":"code-5","dir":"Articles","previous_headings":"","what":"Code","title":"4. Benchmarks of lasR vs. lidR","text":"","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del) dtm = rasterize(1, del) chm = rasterize(1, \"max\") seed = local_maximum(3) tree = region_growing(chm, seed) write = write_las() pipeline = read + del + norm + write + dtm + chm +  seed + tree ans = exec(pipeline, on = ctg, progress = TRUE)"},{"path":[]},{"path":"/articles/multithreading.html","id":"sequential-strategy","dir":"Articles","previous_headings":"","what":"Sequential strategy","title":"Multi-threading in the lasR package","text":"sequential strategy default strategy. However, easier start option explain specificities lasR. sequential processing, name indicates, LAS/LAZ files processed sequentially, nothing parallelized. point cloud one file passes pipeline files waiting processed. represented figure .","code":"set_parallel_strategy(sequential())"},{"path":"/articles/multithreading.html","id":"concurrent-points-strategy","dir":"Articles","previous_headings":"","what":"Concurrent points strategy","title":"Multi-threading in the lasR package","text":"Concurrent points default strategy. LAS/LAZ files processed sequentially. point cloud one file passes pipeline files waiting. Inside pipeline, stages parallelized processing points different threads. core processes subset point cloud. stages parallelized consequently faster, practice, lot stages can easily parallelized way.","code":"set_parallel_strategy(conccurent_points(4))"},{"path":"/articles/multithreading.html","id":"concurrent-files-strategy","dir":"Articles","previous_headings":"","what":"Concurrent files strategy","title":"Multi-threading in the lasR package","text":"LAS/LAZ files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages parallelized. puts lot pressure disk many LAS/LAZ files read simultaneously, also stage can write raster/vector/LAS files simultaneously. Additionally, uses lot memory since many LAS files loaded memory simultaneously. modern fast SSD disks significant amount RAM, fastest option. course, users use cores; otherwise, may run memory. See also benchmarks vignette.","code":"set_parallel_strategy(conccurent_files(4))"},{"path":"/articles/multithreading.html","id":"nested-strategy","dir":"Articles","previous_headings":"","what":"Nested strategy","title":"Multi-threading in the lasR package","text":"LAS/LAZ files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages also parallelized processing points different threads.","code":"set_parallel_strategy(nested(4, 2))"},{"path":"/articles/multithreading.html","id":"special-cases","dir":"Articles","previous_headings":"","what":"Special cases","title":"Multi-threading in the lasR package","text":"lasR, everything written pure C++ except two stages inject user-defined R code use R C API. R multi-threaded, thus calling stages parallel thread-safe crash R session best case deeply corrupt R memory worst case. Consequently, stages protected run concurrently. pipeline stages use R API (orange figure ), stages use R blocking stages waiting (see figure ).  course, depicted diagram , incurs computational time cost. Therefore, users discouraged using stages alternatives available. example, rasterize() offers numerous native metrics coded C++, making custom metrics coded R unnecessary. worth mentioning lidR package face problem core runs different independent R session, thanks future package. approach advantages, one mentioned, also comes several inconveniences overheads. contrast, lasR utilizes one R session process multiple files parallel. multiple files, overhead blocking pipeline stages use R likely less significant pipelines sync, blocking stages longer occur simultaneously thus cease blocking, illustrated figure 8 files 4 cores","code":"rasterize(20, user_function(Z)) callback(user_function(data))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jean-Romain Roussel. Author, maintainer, copyright holder. Martin Isenburg. Copyright holder.            author included LASlib LASzip libraries Benoît St-Onge. Copyright holder.            author included 'chm_prep' function Niels Lohmann. Copyright holder.            author included json parser Volodymyr Bilonenko. Copyright holder.            author included delaunator triangulation","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Roussel J (2024). lasR: Fast Pipable Airborne LiDAR Data Tools. R package version 0.4.1, https://github.com/r-lidar/lasR.","code":"@Manual{,   title = {lasR: Fast and Pipable Airborne LiDAR Data Tools},   author = {Jean-Romain Roussel},   year = {2024},   note = {R package version 0.4.1},   url = {https://github.com/r-lidar/lasR}, }"},{"path":"/index.html","id":"lasr","dir":"","previous_headings":"","what":"Fast and Pipable Airborne LiDAR Data Tools","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"R Package Fast Airborne LiDAR Data Processing lasR package (pronounce laser) intent supersede lidR package, designed much efficient lidR common tasks like production CHM, DTM, tree detection segmentation large coverages. lidR intends tool box make data exploration innovation easy. lasR another hand focuses production, optimized memory speed makes trade aspects development. 📖 Read tutorial start lasR","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"currently plan releasing lasR CRAN. must compile install package Github. Windows must install Rtools first able build package. , use package remotes install lasR: Users can’t rely CRAN versioning system RStudio update button get latest version lasR. loading lasR library(lasR), internal routine checks GitHub latest version prints message new version available. Updates frequent way.","code":"remotes::install_github(\"r-lidar/lasR\") library(lasR) #> lasR 0.1.3 is now available. You are using 0.1.1 #> remotes::install_github(\"r-lidar/lasR\")"},{"path":"/index.html","id":"benchmark","dir":"","previous_headings":"","what":"Benchmark","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"following benchmark compares much time RAM memory takes lasR lidR produce DTM, CHM, raster two metrics derived Z intensity. test performed 120 million points stored 4 LAZ files. details benchmark vignette.","code":""},{"path":"/index.html","id":"main-differences-with-lidr","dir":"","previous_headings":"","what":"Main differences with lidR","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"Introduces concept pipelines, missing lidR, chain multiple operations point cloud optimally. written exclusively C/C++ without single line R. Uses code lidR brings significant speed memory improvements. load point cloud data.frame. point cloud stored C++ structure exposed users. Uses GDAL instead relying terra sf flexibility C++ level. 1 strong dependencies gdal. sf terra installed experience better. details corresponding vignette","code":""},{"path":"/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"lasR developed Laval University.","code":""},{"path":"/index.html","id":"copyright-information","dir":"","previous_headings":"","what":"Copyright Information","title":"Fast and Pipable Airborne LiDAR Data Tools","text":"© 2023-2024 Jean-Romain Roussel Provided GPL-3 license. © 2007-2021 Martin Isenburg - http://rapidlasso.com Provided LGPL license modified R-compliant Jean-Romain Roussel. © 2008-2023 Benoît St-Onge - Geophoton-inc/chm_prep Provided GPL-3 license. Lohmann, N. (2023). JSON Modern C++ (Version 3.11.3) [Computer software]. https://github.com/nlohmann Provided MIT license © 2018 Volodymyr Bilonenko. delfrrr/delaunator-cpp Provided MIT license","code":""},{"path":"/reference/add_extrabytes.html","id":null,"dir":"Reference","previous_headings":"","what":"Add attributes to a LAS file — add_extrabytes","title":"Add attributes to a LAS file — add_extrabytes","text":"According LAS specifications, LAS file contains core defined attributes, XYZ coordinates, intensity, return number, , point. possible add supplementary attributes. stages adds extra bytes attribute points. Values zeroed: underlying point cloud edited support new extrabyte attribute. new attribute can populated later another stage","code":""},{"path":"/reference/add_extrabytes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add attributes to a LAS file — add_extrabytes","text":"","code":"add_extrabytes(data_type, name, description, scale = 1, offset = 0)"},{"path":"/reference/add_extrabytes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add attributes to a LAS file — add_extrabytes","text":"data_type character. data type extra bytes attribute. Can \"uchar\", \"char\", \"ushort\", \"short\", \"uint\", \"int\", \"uint64\", \"int64\", \"float\", \"double\". name character. name extra bytes attribute add file. description character. short description extra bytes attribute add file (32 characters). scale, offset numeric. scale offset data. See LAS specification.","code":""},{"path":"/reference/add_extrabytes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add attributes to a LAS file — add_extrabytes","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package = \"lasR\") fun <- function(data) { data$RAND <- runif(nrow(data), 0, 100); return(data) } pipeline <- reader_las() +   add_extrabytes(\"float\", \"RAND\", \"Random numbers\") +   callback(fun, expose = \"xyz\") exec(pipeline, on = f) #> NULL"},{"path":"/reference/add_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Add RGB attributes to a LAS file — add_rgb","title":"Add RGB attributes to a LAS file — add_rgb","text":"Modifies LAS format convert format RGB attributes. Values zeroed: underlying point cloud edited transformed format supports RGB. RGB can populated later another stage. point cloud already RGB, nothing happens, RGB values preserved.","code":""},{"path":"/reference/add_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"add_rgb()"},{"path":"/reference/add_rgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\")  pipeline <- add_rgb() + write_las() exec(pipeline, on = f) #> [1] \"/tmp/RtmpnYzbWe/Example.las\""},{"path":"/reference/callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a user-defined function on the point cloud — callback","title":"Call a user-defined function on the point cloud — callback","text":"Call user-defined function point cloud. function receives data.frame point cloud. first input must point cloud. function returns anything data.frame number points, output stored returned end. However, output data.frame number points, updates point cloud. function can, therefore, used modify point cloud using user-defined function.","code":""},{"path":"/reference/callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a user-defined function on the point cloud — callback","text":"","code":"callback(fun, expose = \"xyz\", ..., drop_buffer = FALSE, no_las_update = FALSE)"},{"path":"/reference/callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a user-defined function on the point cloud — callback","text":"fun numeric. resolution raster. expose character. Expose attributes interest save memory (see details). ... parameters function fun drop_buffer bool. false, expose point buffer. no_las_update bool. user-defined function returns data.frame, supposed update point cloud. Can disabled.","code":""},{"path":"/reference/callback.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Call a user-defined function on the point cloud — callback","text":"lasR, point cloud exposed R data.frame like lidR. stored internally C++ structure seen modified directly users using R code. callback function stage allows direct interaction point cloud copying temporarily data.frame apply user-defined function.expose: 'expose' argument specifies data actually exposed R. example, 'xyzia' means x, y, z coordinates, intensity, scan angle loaded. supported entries t - gpstime, - scan angle, - intensity, n - number returns, r - return number, c - classification, s - synthetic flag, k - keypoint flag, w - withheld flag, o - overlap flag (format 6+), u - user data, p - point source ID, e - edge flight line flag, d - direction scan flag, R - red channel RGB color, G - green channel RGB color, B - blue channel RGB color, N - near-infrared channel, C - scanner channel (format 6+) Also numbers 1 9 extra bytes data numbers 1 9. 0 enables extra bytes loaded, '*' wildcard enables everything loaded LAS file.","code":""},{"path":[]},{"path":"/reference/callback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a user-defined function on the point cloud — callback","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  # There is no function in lasR to read the data in R. Let's create one read_las <- function(f) {   load <- function(data) { return(data) }   read <- reader_las()   call <- callback(load, expose = \"xyzi\", no_las_update = TRUE)   return (exec(read + call, on = f)) } las <- read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123  convert_intensity_in_range <- function(data, min, max) {   i <- data$Intensity   i <- ((i - min(i)) / (max(i) - min(i))) * (max - min) + min   i[i < min] <- min   i[i > max] <- max   data$Intensity <- as.integer(i)   return(data) }  read <- reader_las() call <- callback(convert_intensity_in_range, expose = \"xyzi\", min = 0, max = 255) write <- write_las() pipeline <- read + call + write ans <- exec(pipeline, on = f)  las <- read_las(ans) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340       137 #> 2 273357.2 5274359 806.5635        72 #> 3 273357.2 5274358 806.0248       140 #> 4 273357.2 5274510 809.6303        57 #> 5 273357.2 5274509 809.3880       133 #> 6 273357.2 5274508 809.4847         7"},{"path":"/reference/chm.html","id":null,"dir":"Reference","previous_headings":"","what":"Canopy Height Model — chm","title":"Canopy Height Model — chm","text":"Create Canopy Height Model using triangulate rasterize.","code":""},{"path":"/reference/chm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canopy Height Model — chm","text":"","code":"chm(res = 1, tin = FALSE, ofile = tempfile(fileext = \".tif\"))"},{"path":"/reference/chm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canopy Height Model — chm","text":"res numeric. resolution raster. tin bool. default CHM point--raster based methods .e. pixel assigned elevation highest point. tin = TRUE CHM triangulation-based model. first returns triangulated interpolated. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"/reference/chm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Canopy Height Model — chm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader(f) + chm()"},{"path":"/reference/classify_isolated_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify isolated points — classify_isolated_points","title":"Classify isolated points — classify_isolated_points","text":"stage identifies points points surrounding 3 x 3 x 3 = 27 voxels edits points assign target classification. Used class 18, classifies points noise similar lasnoise LAStools. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/classify_isolated_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify isolated points — classify_isolated_points","text":"","code":"classify_isolated_points(res = 5, n = 6L, class = 18L)"},{"path":"/reference/classify_isolated_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify isolated points — classify_isolated_points","text":"res numeric. Resolution voxels. n integer. maximal number 'points' 27 voxels. class integer. class assign points match condition.","code":""},{"path":"/reference/delete_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter and delete points — delete_points","title":"Filter and delete points — delete_points","text":"Remove points point cloud. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/delete_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter and delete points — delete_points","text":"","code":"delete_points(filter = \"\")"},{"path":"/reference/delete_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter and delete points — delete_points","text":"filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters.","code":""},{"path":"/reference/delete_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter and delete points — delete_points","text":"","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") read <- reader_las() filter <- delete_points(keep_z_above(4))  pipeline <- read + summarise() + filter + summarise() exec(pipeline, on = f) #> $summary #> $summary$npoints #> [1] 81590 #>  #> $summary$nsingle #> [1] 34337 #>  #> $summary$nwithheld #> [1] 0 #>  #> $summary$nsynthetic #> [1] 0 #>  #> $summary$npoints_per_return #>     1     2     3     4  #> 55756 21493  3999   342  #>  #> $summary$npoints_per_class #>     1     2  #> 74201  7389  #>  #> $summary$z_histogram #>     0     2     4     6     8    10    12    14    16    18    20    22    24  #> 11031  1256  2476  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156  #>    26    28    30  #>   955   103     4  #>  #> $summary$i_histogram #>     0    25    50    75   100   125   150   175   200   225   250   275   300  #> 25056 42878 13161   312    95    30    21    20     3     1     6     0     1  #>   325   350   375   400   425   450   475   500   525   550   575  #>     1     0     1     0     0     1     0     1     1     0     1  #>  #>  #> $summary #> $summary$npoints #> [1] 68328 #>  #> $summary$nsingle #> [1] 26693 #>  #> $summary$nwithheld #> [1] 0 #>  #> $summary$nsynthetic #> [1] 0 #>  #> $summary$npoints_per_return #>     1     2     3     4  #> 47919 18297  2058    54  #>  #> $summary$npoints_per_class #>     1  #> 68328  #>  #> $summary$z_histogram #>     4     6     8    10    12    14    16    18    20    22    24    26    28  #>  1501  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156   955   103  #>    30  #>     4  #>  #> $summary$i_histogram #>     0    25    50    75  #> 18734 38226 11359     9  #>  #>"},{"path":"/reference/deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated — deprecated","title":"Deprecated — deprecated","text":"Deprecated function replaced exec reader_las","code":""},{"path":"/reference/deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated — deprecated","text":"","code":"processor(pipeline, ncores = half_cores(), progress = FALSE, ...)  reader(x, filter = \"\", buffer = 0, ...)  reader_coverage(x, filter = \"\", buffer = 0, ...)  reader_circles(x, xc, yc, r, filter = \"\", buffer = 0, ...)  reader_rectangles(x, xmin, ymin, xmax, ymax, filter = \"\", buffer = 0, ...)"},{"path":"/reference/deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated — deprecated","text":"pipeline LASRpipeline. serie algorithms called order ncores integer. Number cores use. stages steps stages parallelised overall one file process time. progress boolean. Displays progress bar. ... passed readers x Can paths files use, path folder files stored, path [virtual point cloud](https://www.lutraconsulting.co.uk/blog/2023/06/08/virtual-point-clouds/) file `data.frame` containing hte point cloud. supports also `LAScatalog` `LAS` objects `lidR`. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. buffer numeric. file read buffer. default 0, mean file buffered. means internal routine knows buffer needed pick greatest value internal suggestion provided value. xc, yc, r numeric. Circle centres radius radii. xmin, ymin, xmax, ymax numeric. Coordinates rectangles","code":""},{"path":"/reference/dtm.html","id":null,"dir":"Reference","previous_headings":"","what":"Digital Terrain Model — dtm","title":"Digital Terrain Model — dtm","text":"Create Digital Terrain Model using triangulate rasterize.","code":""},{"path":"/reference/dtm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Digital Terrain Model — dtm","text":"","code":"dtm(res = 1, add_class = NULL, ofile = tempfile(fileext = \".tif\"))"},{"path":"/reference/dtm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Digital Terrain Model — dtm","text":"res numeric. resolution raster. add_class integer. default triangulates using ground points (class 2). possible provide additional classes 9 water. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"/reference/dtm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Digital Terrain Model — dtm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader(f) + dtm()"},{"path":"/reference/exec.html","id":null,"dir":"Reference","previous_headings":"","what":"Process the pipeline — exec","title":"Process the pipeline — exec","text":"Process pipeline. Every functions package nothing. function must called pipeline order actually process point-cloud. process parallel using multiple cores, refer multithreading page.","code":""},{"path":"/reference/exec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process the pipeline — exec","text":"","code":"exec(pipeline, on, with = NULL, ...)"},{"path":"/reference/exec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process the pipeline — exec","text":"pipeline pipeline. serie stages called order Can paths files use, path folder files stored, path virtual point cloud file data.frame containing point cloud. supports also LAScatalog LAS objects lidR. list. list options control pipeline executed. includes options control parallel processing, progress bar display, tile buffering . See set_exec_options details available options. ... processing options can explicitly named passed outside argument. See set_exec_options","code":""},{"path":[]},{"path":"/reference/exec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process the pipeline — exec","text":"","code":"if (FALSE) { f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  read <- reader_las() tri <- triangulate(15) dtm <- rasterize(5, tri) lmf <- local_maximum(5) met <- rasterize(2, \"imean\") pipeline <- read + tri + dtm + lmf + met ans <- exec(pipeline, on = f, with = list(progress = TRUE)) }"},{"path":"/reference/filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Point filters — filters","title":"Point filters — filters","text":"lasR uses LASlib/LASzip, library developed Martin Isenburg read write LAS/LAZ files. Thus, flags available LAStools also available lasR. Filters strings put filter arguments lasR algorithms. list available strings accessible filter_usage. convenience, useful filters associated function returns corresponding string.","code":""},{"path":"/reference/filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Point filters — filters","text":"","code":"keep_class(x)  drop_class(x)  keep_first()  drop_first()  keep_ground()  drop_ground()  keep_noise()  drop_noise()  keep_z_above(x)  drop_z_above(x)  keep_z_below(x)  drop_z_below(x)  drop_duplicates()  filter_usage()  # S3 method for laslibfilter print(x, ...)  # S3 method for laslibfilter +(e1, e2)"},{"path":"/reference/filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Point filters — filters","text":"x numeric integer function filter used. ... Unused. e1, e2 lasR objects.","code":""},{"path":"/reference/filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Point filters — filters","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") filter_usage() #> Filter points based on their coordinates. #>   -keep_tile 631000 4834000 1000 (ll_x ll_y size) #>   -keep_circle 630250.00 4834750.00 100 (x y radius) #>   -keep_xy 630000 4834000 631000 4836000 (min_x min_y max_x max_y) #>   -drop_xy 630000 4834000 631000 4836000 (min_x min_y max_x max_y) #>   -keep_x 631500.50 631501.00 (min_x max_x) #>   -drop_x 631500.50 631501.00 (min_x max_x) #>   -drop_x_below 630000.50 (min_x) #>   -drop_x_above 630500.50 (max_x) #>   -keep_y 4834500.25 4834550.25 (min_y max_y) #>   -drop_y 4834500.25 4834550.25 (min_y max_y) #>   -drop_y_below 4834500.25 (min_y) #>   -drop_y_above 4836000.75 (max_y) #>   -keep_z 11.125 130.725 (min_z max_z) #>   -drop_z 11.125 130.725 (min_z max_z) #>   -drop_z_below 11.125 (min_z) #>   -drop_z_above 130.725 (max_z) #>   -keep_xyz 620000 4830000 100 621000 4831000 200 (min_x min_y min_z max_x max_y max_z) #>   -drop_xyz 620000 4830000 100 621000 4831000 200 (min_x min_y min_z max_x max_y max_z) #>   -drop_duplicates #> Filter points based on their return numbering. #>   -keep_first -first_only -drop_first #>   -keep_last -last_only -drop_last #>   -keep_second_last -drop_second_last #>   -keep_first_of_many -keep_last_of_many #>   -drop_first_of_many -drop_last_of_many #>   -keep_middle -drop_middle #>   -keep_return 1 2 3 #>   -drop_return 3 4 #>   -keep_single -drop_single #>   -keep_double -drop_double #>   -keep_triple -drop_triple #>   -keep_quadruple -drop_quadruple #>   -keep_number_of_returns 5 #>   -drop_number_of_returns 0 #> Filter points based on the scanline flags. #>   -drop_scan_direction 0 #>   -keep_scan_direction_change #>   -keep_edge_of_flight_line #> Filter points based on their intensity. #>   -keep_intensity 20 380 #>   -drop_intensity_below 20 #>   -drop_intensity_above 380 #>   -drop_intensity_between 4000 5000 #> Filter points based on classifications or flags. #>   -keep_class 1 3 7 #>   -drop_class 4 2 #>   -keep_extended_class 43 #>   -drop_extended_class 129 135 #>   -drop_synthetic -keep_synthetic #>   -drop_keypoint -keep_keypoint #>   -drop_withheld -keep_withheld #>   -drop_overlap -keep_overlap #> Filter points based on their user data. #>   -keep_user_data 1 #>   -drop_user_data 255 #>   -keep_user_data_below 50 #>   -keep_user_data_above 150 #>   -keep_user_data_between 10 20 #>   -drop_user_data_below 1 #>   -drop_user_data_above 100 #>   -drop_user_data_between 10 40 #> Filter points based on their point source ID. #>   -keep_point_source 3 #>   -keep_point_source_between 2 6 #>   -drop_point_source 27 #>   -drop_point_source_below 6 #>   -drop_point_source_above 15 #>   -drop_point_source_between 17 21 #> Filter points based on their scan angle. #>   -keep_scan_angle -15 15 #>   -drop_abs_scan_angle_above 15 #>   -drop_abs_scan_angle_below 1 #>   -drop_scan_angle_below -15 #>   -drop_scan_angle_above 15 #>   -drop_scan_angle_between -25 -23 #> Filter points based on their gps time. #>   -keep_gps_time 11.125 130.725 #>   -drop_gps_time_below 11.125 #>   -drop_gps_time_above 130.725 #>   -drop_gps_time_between 22.0 48.0 #> Filter points based on their RGB/CIR/NIR channels. #>   -keep_RGB_red 1 1 #>   -drop_RGB_red 5000 20000 #>   -keep_RGB_green 30 100 #>   -drop_RGB_green 2000 10000 #>   -keep_RGB_blue 0 0 #>   -keep_RGB_nir 64 127 #>   -keep_RGB_greenness 200 65535 #>   -keep_NDVI 0.2 0.7 -keep_NDVI_from_CIR -0.1 0.5 #>   -keep_NDVI_intensity_is_NIR 0.4 0.8 -keep_NDVI_green_is_NIR -0.2 0.2 #> Filter points based on their wavepacket. #>   -keep_wavepacket 0 #>   -drop_wavepacket 3 #> Filter points based on extra attributes. #>   -keep_attribute_above 0 5.0 #>   -drop_attribute_below 1 1.5 #> Filter points with simple thinning. #>   -keep_every_nth 2 -drop_every_nth 3 #>   -keep_random_fraction 0.1 #>   -keep_random_fraction 0.1 4711 #>   -thin_with_grid 1.0 #>   -thin_pulses_with_time 0.0001 #>   -thin_points_with_time 0.000001 #> Boolean combination of filters. #>   -filter_and gnd = keep_class(c(2,9)) reader(f, gnd) #>  ----------- #> reader_las (uid:cgWfAl) #>   files : Topography.las #>   filter : -keep_class 2 9  #>   buffer : 0  #>   output :   #> ----------- triangulate(filter = keep_ground()) #>  ----------- #> triangulate (uid:MkPN1W) #>   max_edge : 0  #>   filter : -keep_class 2  #>   output :   #>   use_attribute : Z  #> ----------- rasterize(1, \"max\", filter = \"-drop_z_below 5\") #>  ----------- #> rasterize (uid:RZorR1) #>   res : 1  #>   window : 1  #>   method : max  #>   filter : -drop_z_below 5  #>   output : /tmp/RtmpnYzbWe/file1fb96f036064.tif  #> -----------"},{"path":"/reference/hulls.html","id":null,"dir":"Reference","previous_headings":"","what":"Contour of a point cloud — hulls","title":"Contour of a point cloud — hulls","text":"stage uses Delaunay triangulation computes contour. contour strict Delaunay triangulation convex hull, lasR, triangulation max_edge argument. Thus, contour might convex hull holes. Used without triangulation returns bouding box points.","code":""},{"path":"/reference/hulls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contour of a point cloud — hulls","text":"","code":"hulls(mesh = NULL, ofile = tempgpkg())"},{"path":"/reference/hulls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contour of a point cloud — hulls","text":"mesh NULL LASRalgorithm. triangulate stage. NULL take bounding box header file. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"/reference/hulls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contour of a point cloud — hulls","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\") read <- reader_las() tri <- triangulate(20, filter = keep_ground()) contour <- hulls(tri) pipeline <- read + tri + contour ans <- exec(pipeline, on = f) plot(ans)"},{"path":"/reference/lasR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lasR: airborne LiDAR for forestry applications — lasR-package","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"lasR provides set tools process efficiently airborne LiDAR data forestry contexts. package works .las .laz files. toolbox includes algorithms DSM, CHM, DTM, ABA, normalisation, tree detection, tree segmentation, tree delineation, colourization, validation tools, well processing engine process broad LiDAR coverage split many files efficiently.","code":""},{"path":[]},{"path":"/reference/lasR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"Maintainer: Jean-Romain Roussel jean-romain.roussel.1@ulaval.ca [copyright holder] contributors: Martin Isenburg (author included LASlib LASzip libraries) [copyright holder] Benoît St-Onge (author included 'chm_prep' function) [copyright holder] Niels Lohmann (author included json parser) [copyright holder] Volodymyr Bilonenko (author included delaunator triangulation) [copyright holder]","code":""},{"path":"/reference/load_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a raster for later use — load_raster","title":"Load a raster for later use — load_raster","text":"Load raster disk file later use. example, load DTM feed transform_with stage load CHM feed pit_fill stage. raster never loaded entirely. Internally, chunks corresponding currently processed point cloud loaded. careful: internally, raster read float matter original datatype.","code":""},{"path":"/reference/load_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a raster for later use — load_raster","text":"","code":"load_raster(file, band = 1L)"},{"path":"/reference/load_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a raster for later use — load_raster","text":"file character. Path raster file. band integer. band load. reads loads single band.","code":""},{"path":"/reference/load_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a raster for later use — load_raster","text":"","code":"r <- system.file(\"extdata/bcts\", \"bcts_dsm_5m.tif\", package = \"lasR\") f <- paste0(system.file(package = \"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  # In the following pipeline, neither load_raster nor pit_fill process any points. # The internal engine is capable of knowing that, and the LAS files won't actually be # read. Yet the raster r will be processed by chunk following the LAS file pattern. rr <- load_raster(r) pipeline <- rr + pit_fill(rr) ans <- exec(pipeline, on = f, verbose = FALSE)"},{"path":"/reference/local_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Maximum — local_maximum","title":"Local Maximum — local_maximum","text":"Local Maximum stage identifies points locally maximum. window size fixed circular. stage modify point cloud. produces derived product vector format. function local_maximum_raster applies raster instead point cloud","code":""},{"path":"/reference/local_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Maximum — local_maximum","text":"","code":"local_maximum(   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg(),   use_attribute = \"Z\" )  local_maximum_raster(   raster,   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg() )"},{"path":"/reference/local_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Maximum — local_maximum","text":"ws numeric. Diameter moving window used detect local maxima units input data (usually meters). min_height numeric. Minimum height local maximum. Threshold point local maximum. Default 2. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. default local maximum performed coordinate Z. Can also name extra bytes attribute 'HAG' exists. Can also 'Intensity' probably use case one. raster LASRalgorithm. stage produces raster.","code":""},{"path":"/reference/local_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Maximum — local_maximum","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package = \"lasR\") read <- reader_las() lmf <- local_maximum(5) ans <- exec(read + lmf, on = f) ans #> Simple feature collection with 177 features and 5 fields #> Geometry type: POINT #> Dimension:     XYZ #> Bounding box:  xmin: 481260 ymin: 3812921 xmax: 481349.8 ymax: 3813011 #> z_range:       zmin: 2.42 zmax: 32.07 #> Projected CRS: NAD83 / UTM zone 12N #> # A tibble: 177 × 6 #>    Intensity gpstime ReturnNumber Classification ScanAngle #>        <int>   <dbl>        <int>          <int>     <dbl> #>  1       141 151388.            1              1        -4 #>  2       115 149929.            1              1        16 #>  3       116 151388.            1              1        -8 #>  4        13 149930.            1              1        17 #>  5       152 149930.            1              1        17 #>  6       113 149930.            1              1        17 #>  7        82 151388.            1              1        -3 #>  8        86 149930.            1              1        16 #>  9       103 151388.            1              1        -6 #> 10       125 150747.            1              1        -9 #> # ℹ 167 more rows #> # ℹ 1 more variable: geom <POINT [m]>  chm <- rasterize(1, \"max\") lmf <- local_maximum_raster(chm, 5) ans <- exec(read + chm + lmf, on = f) # terra::plot(ans$rasterize) # plot(ans$local_maximum, add = T, pch = 19)"},{"path":"/reference/multithreading.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel processing tools — multithreading","title":"Parallel processing tools — multithreading","text":"lasR uses OpenMP paralellize internal C++ code. set_parallel_strategy() globally changes strategy used process point clouds. sequential(), concurrent_files(), concurrent_points(), nested() functions assign parallelization strategy (see Details). has_omp_support() tells lasR package compiled support OpenMP unlikely case MacOS.","code":""},{"path":"/reference/multithreading.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel processing tools — multithreading","text":"","code":"set_parallel_strategy(strategy)  unset_parallel_strategy()  get_parallel_strategy()  ncores()  half_cores()  sequential()  concurrent_files(ncores = half_cores())  concurrent_points(ncores = half_cores())  nested(ncores = ncores()/4L, ncores2 = 2L)  has_omp_support()"},{"path":"/reference/multithreading.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel processing tools — multithreading","text":"strategy object returned one sequential(), concurrent_points(), concurrent_files() nested(). ncores integer. Number cores. ncores2 integer.  Number cores. nested strategy ncores number concurrent files ncores2 number concurrent points.","code":""},{"path":"/reference/multithreading.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel processing tools — multithreading","text":"4 strategies parallel processing: sequential parallelization : sequential() concurrent-points Point cloud files processed sequentially one one. Inside pipeline, stages parallelized able process multiple points simultaneously. stages natively parallelized. E.g. concurrent_points(4) concurrent-files Files processed parallel. Several files loaded memory processed simultaneously. entire pipeline parallelized, inside stage, points processed sequentially. E.g. concurrent_files(4) nested Files processed parallel. Several files loaded memory processed simultaneously, inside stages, points processed parallel. E.g. nested(4,2) concurrent-files likely desirable fastest option. However, uses memory loads multiple files. default concurrent_points(half_cores()) can changed globally using e.g. set_parallel_strategy(concurrent_files(4))","code":""},{"path":"/reference/multithreading.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel processing tools — multithreading","text":"","code":"if (FALSE) { f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  pipeline <- reader_las() + rasterize(2, \"imean\")  ans <- exec(pipeline, on = f, progress = TRUE, ncores = concurrent_files(4))  set_parallel_strategy(concurrent_files(4)) ans <- exec(pipeline, on = f, progress = TRUE) }"},{"path":"/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize the point cloud — normalize","title":"Normalize the point cloud — normalize","text":"Normalize point cloud using triangulate transform_with","code":""},{"path":"/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize the point cloud — normalize","text":"","code":"normalize(extrabytes = FALSE)"},{"path":"/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize the point cloud — normalize","text":"extrabytes bool. FALSE coordinate Z point cloud modified becomes height ground (HAG). TRUE coordinate Z modified new extrabytes attribute named 'HAG' added point cloud.","code":""},{"path":[]},{"path":"/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize the point cloud — normalize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader(f) + normalize() + write_las()"},{"path":"/reference/pit_fill.html","id":null,"dir":"Reference","previous_headings":"","what":"Pits and spikes filling — pit_fill","title":"Pits and spikes filling — pit_fill","text":"Pits spikes filling raster. Typically used post-processing CHM. algorithm St-Onge 2008 (see reference).","code":""},{"path":"/reference/pit_fill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pits and spikes filling — pit_fill","text":"","code":"pit_fill(   raster,   lap_size = 3L,   thr_lap = 0.1,   thr_spk = -0.1,   med_size = 3L,   dil_radius = 0L,   ofile = temptif() )"},{"path":"/reference/pit_fill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pits and spikes filling — pit_fill","text":"raster LASRalgorithm. stage produces raster. lap_size integer. Size Laplacian filter kernel (integer value, pixels). thr_lap numeric. Threshold Laplacian value detecting cavity (values value considered cavity). positive value. thr_spk numeric. Threshold Laplacian value detecting spike (values value considered spike). negative value. med_size integer. Size median filter kernel (integer value, pixels). dil_radius integer. Dilation radius (integer value, pixels). ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/pit_fill.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pits and spikes filling — pit_fill","text":"St-Onge, B., 2008. Methods improving quality true orthomosaic Vexcel UltraCam images created using alidar digital surface model, Proceedings Silvilaser 2008, Edinburgh, 555-562. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=81365288221f3ac34b51a82e2cfed8d58defb10e","code":""},{"path":"/reference/pit_fill.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pits and spikes filling — pit_fill","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader_las(filter = keep_first()) tri <- triangulate() chm <- rasterize(0.25, tri) pit <- pit_fill(chm) u <- exec(reader + tri + chm + pit, on = f)  chm <- u[[1]] sto <- u[[2]]  #terra::plot(c(chm, sto), col = lidR::height.colors(25))"},{"path":"/reference/rasterize.html","id":null,"dir":"Reference","previous_headings":"","what":"Rasterize a point cloud — rasterize","title":"Rasterize a point cloud — rasterize","text":"Rasterize point cloud using different approaches. stage modify point cloud. produces derived product raster format.","code":""},{"path":"/reference/rasterize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rasterize a point cloud — rasterize","text":"","code":"rasterize(res, operators = \"max\", filter = \"\", ofile = temptif())"},{"path":"/reference/rasterize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rasterize a point cloud — rasterize","text":"res numeric. resolution raster. Can vector two resolutions. case correspond x y resolution buffered rasterization. (see section 'Buffered' examples) operators Can character vector. \"min\", \"max\" \"count\" accepted well many others (see section 'Operators'). Can also rasterize triangulation input LASRalgorithm triangulation (see examples). Can also user-defined expression (see example section 'Operators'). filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/rasterize.html","id":"operators","dir":"Reference","previous_headings":"","what":"Operators","title":"Rasterize a point cloud — rasterize","text":"operators string vector strings, function employs internally optimized metrics. available metrics include \"zmax\", \"zmin\", \"zmean\", \"zmedian\", \"zsd\", \"zcv\", \"zpXX\" Z coordinates. , \"zpXX\" represents XXth percentile, instance, \"zp95\" signifies 95th percentile. Similarly, metrics accessible letter \"\" intensity, \"imax\" others. Additionally, \"count\" another available metric.  operators user-defined expression, function return either vector numbers list containing atomic numbers. assign band name raster, vector list must named accordingly. following valid operators:","code":"f = function(x) { return(mean(x)) } g = function(x,y) { return(c(avg = mean(x), med = median(y))) } h = function(x) { return(list(a = mean(x), b = median(x))) } rasterize(10, f(Intensity)) rasterize(10, g(Z, Intensity)) rasterize(10, h(Z))"},{"path":"/reference/rasterize.html","id":"buffered","dir":"Reference","previous_headings":"","what":"Buffered","title":"Rasterize a point cloud — rasterize","text":"argument res vector two numbers, first number represents resolution output raster, second number represents size windows used compute metrics. approach called Buffered Area Based Approach (BABA). classical rasterization, metrics computed independently pixel. example, predicting resource typically involves computing metrics 400 square meter pixel, resulting raster resolution 20 meters. possible achieve finer granularity method. However, buffered rasterization, possible compute raster resolution 10 meters (.e., computing metrics every 10 meters) using 20 x 20 windows metric computation. case, windows overlap, essentially creating moving window effect. option apply rasterizing triangulation, second value considered case.","code":""},{"path":"/reference/rasterize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rasterize a point cloud — rasterize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri  <- triangulate(filter = keep_ground()) dtm  <- rasterize(1, tri) # input is a triangulation stage avgi <- rasterize(10, mean(Intensity)) # input is a user expression chm  <- rasterize(2, \"max\") # input is a character vector pipeline <- read + tri + dtm + avgi + chm ans <- exec(pipeline, on = f) ans[[1]] #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1fb9695ce66e.tif  #> name        : file1fb9695ce66e  ans[[2]] #> class       : SpatRaster  #> dimensions  : 30, 30, 1  (nrow, ncol, nlyr) #> resolution  : 10, 10  (x, y) #> extent      : 273350, 273650, 5274350, 5274650  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1fb917dcbea0.tif  #> name        : file1fb917dcbea0  ans[[3]] #> class       : SpatRaster  #> dimensions  : 144, 144, 1  (nrow, ncol, nlyr) #> resolution  : 2, 2  (x, y) #> extent      : 273356, 273644, 5274356, 5274644  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1fb963d9208a.tif  #> name        : max   # Demonstration of buffered rasterization  # A good resolution for computing point density is 5 meters. c0 <- rasterize(5, \"count\")  # Computing point density at too fine a resolution doesn't make sense since there is # either zero or one point per pixel. Therefore, producing a point density raster with # a 2 m resolution is not feasible with classical rasterization. c1 <- rasterize(2, \"count\")  # Using a buffered approach, we can produce a raster with a 2-meter resolution where # the metrics for each pixel are computed using a 5-meter window. c2  <- rasterize(c(2,5), \"count\")  pipeline = read + c0 + c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/25)  # divide by 25 to get the density  terra::plot(res[[2]]/4)   # divide by 4 to get the density  terra::plot(res[[3]]/25)  # divide by 25 to get the density"},{"path":"/reference/reader_las.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the pipeline — reader_las","title":"Initialize the pipeline — reader_las","text":"first stage must called pipeline. stage nothing returns nothing associated another processing stage. initializes pipeline. reader_las() main function dispatches functions. reader_las_coverage() processes entire point cloud. reader_las_circles() reader_las_rectangles() read process selected regions interest. chosen reader options .e. using reader_las() can omitted.","code":""},{"path":"/reference/reader_las.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the pipeline — reader_las","text":"","code":"reader_las(filter = \"\", ...)  reader_las_coverage(filter = \"\", ...)  reader_las_circles(xc, yc, r, filter = \"\", ...)  reader_las_rectangles(xmin, ymin, xmax, ymax, filter = \"\", ...)"},{"path":"/reference/reader_las.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the pipeline — reader_las","text":"filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ... passed readers xc, yc, r numeric. Circle centres radius radii. xmin, ymin, xmax, ymax numeric. Coordinates rectangles","code":""},{"path":"/reference/reader_las.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the pipeline — reader_las","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  pipeline <- reader_las() + rasterize(10, \"zmax\") ans <- exec(pipeline, on = f) # terra::plot(ans)  pipeline <- reader_las(filter = keep_z_above(1.3)) + rasterize(10, \"zmean\") ans <- exec(pipeline, on = f) # terra::plot(ans)  # read_las() with no option can be omitted ans <- exec(rasterize(10, \"zmax\"), on = f) # terra::plot(ans)  # Perform a query and apply the pipeline on a subset pipeline = reader_las_circles(273500, 5274500, 20) + rasterize(2, \"zmax\") ans <- exec(pipeline, on = f) #> 1 files do not have a spatial index. Spatial indexing speeds up tile buffering and spatial queries drastically. #> Files will be indexed on-the-fly. This will take some extra time now but will speed up everything later. # terra::plot(ans)  # Perform a query and apply the pipeline on a subset with 1 output files per query ofile = paste0(tempdir(), \"/*_chm.tif\") pipeline = reader_las_circles(273500, 5274500, 20) + rasterize(2, \"zmax\", ofile = ofile) ans <- exec(pipeline, on = f) # terra::plot(ans)"},{"path":"/reference/region_growing.html","id":null,"dir":"Reference","previous_headings":"","what":"Region growing — region_growing","title":"Region growing — region_growing","text":"Region growing individual tree segmentation based Dalponte Coomes (2016) algorithm (see reference). Note stage strictly performs segmentation, original method described manuscript also performs pre- post-processing tasks. , tasks expected done user separate functions.","code":""},{"path":"/reference/region_growing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Region growing — region_growing","text":"","code":"region_growing(   raster,   seeds,   th_tree = 2,   th_seed = 0.45,   th_cr = 0.55,   max_cr = 20,   ofile = temptif() )"},{"path":"/reference/region_growing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Region growing — region_growing","text":"raster LASRalgoritm. stage producing raster. seeds LASRalgoritm. stage producing points used seeds. th_tree numeric. Threshold pixel tree. Default 2. th_seed numeric. Growing threshold 1. See reference Dalponte et al. 2016. pixel added region height greater tree height multiplied value. 0 1. Default 0.45. th_cr numeric. Growing threshold 2. See reference Dalponte et al. 2016. pixel added region height greater current mean height region multiplied value. 0 1. Default 0.55. max_cr numeric. Maximum value crown diameter detected tree (data units). Default 20. CAREFUL algorithm exists lidR package parameter pixels lidR. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/region_growing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Region growing — region_growing","text":"Dalponte, M. Coomes, D. . (2016), Tree-centric mapping forest carbon density airborne laser scanning hyperspectral data. Methods Ecol Evol, 7: 1236–1245. doi:10.1111/2041-210X.12575.","code":""},{"path":"/reference/region_growing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Region growing — region_growing","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader_las(filter = keep_first()) chm <- rasterize(1, \"max\") lmx <- local_maximum_raster(chm, 5) tree <- region_growing(chm, lmx, max_cr = 10) u <- exec(reader + chm + lmx + tree, on = f)  # terra::plot(u$rasterize) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5) # terra::plot(u$region_growing, col = rainbow(150)) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5)"},{"path":"/reference/sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the point cloud keeping one random point per units — sampling_voxel","title":"Sample the point cloud keeping one random point per units — sampling_voxel","text":"Sample point cloud, keeping one random point per pixel per voxel. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the point cloud keeping one random point per units — sampling_voxel","text":"","code":"sampling_voxel(res = 2, filter = \"\")  sampling_pixel(res = 2, filter = \"\")"},{"path":"/reference/sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the point cloud keeping one random point per units — sampling_voxel","text":"res numeric. voxel resolution filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters.","code":""},{"path":"/reference/sampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the point cloud keeping one random point per units — sampling_voxel","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() vox <- sampling_voxel(5) write <- write_las() pipeline <- read + vox + write exec(pipeline, on = f) #> [1] \"/tmp/RtmpnYzbWe/Topography.las\""},{"path":"/reference/set_exec_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global processing options — set_exec_options","title":"Set global processing options — set_exec_options","text":"Set global processing options exec function. default, pipelines executed without progress bar, processing one file time sequentially. following options can passed exec() function four ways. See details.","code":""},{"path":"/reference/set_exec_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global processing options — set_exec_options","text":"","code":"set_exec_options(   ncores = NULL,   progress = NULL,   buffer = NULL,   chunk = NULL,   ... )  unset_exec_option()"},{"path":"/reference/set_exec_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global processing options — set_exec_options","text":"ncores object returned one sequential(), concurrent_points(), concurrent_files, nested(). See multithreading. progress boolean. Displays progress bar. buffer numeric. file read buffer. default NULL, mean file buffered. means internal routine knows buffer needed pick greatest value internal suggestion value. chunk numeric. default, collection files processed file (chunk = NULL chunk = 0). possible process arbitrary-sized chunks. useful e.g., processing collections large files processing massive copc file. ... internal options exposed users.","code":""},{"path":"/reference/set_exec_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set global processing options — set_exec_options","text":"4 ways pass processing options, important understand precedence rules: first option explicitly naming option. option deprecated used convenience backward compatibility. second option passing list argument. option explicit preferred. argument takes precedence explicit arguments. third option using LAScatalog lidR package. LAScatalog already carries processing options respected lasR package. options LAScatalog take precedence. last option setting global processing options. global precedence mainly intended provide way users override options access exec() function. may happen developer creates function executes pipeline internally, users provide options. default lasR already set global options ncores. Thus providing ncores effect unless call unset_parallel_strategy first.","code":"exec(pipeline, on = f, progress = TRUE) exec(pipeline, on = f, with = list(progress = TRUE, chunk = 500)) exec(pipeline, on = ctg) set_exec_options(progress = TRUE, ncores = concurrent_files(2)) exec(pipeline, on = f)"},{"path":[]},{"path":"/reference/summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary — summarise","title":"Summary — summarise","text":"Summarize dataset counting number points, first returns, classes. also produces histogram Z Intensity. stage modify point cloud. produces summary `list`.","code":""},{"path":"/reference/summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary — summarise","text":"","code":"summarise(zwbin = 2, iwbin = 25, filter = \"\")"},{"path":"/reference/summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary — summarise","text":"zwbin, iwbin numeric. Width bins histograms Z Intensity. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters.","code":""},{"path":"/reference/summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary — summarise","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() pipeline <- read + summarise() ans <- exec(pipeline, on = f) ans #> $npoints #> [1] 73403 #>  #> $nsingle #> [1] 31294 #>  #> $nwithheld #> [1] 0 #>  #> $nsynthetic #> [1] 0 #>  #> $npoints_per_return #>     1     2     3     4     5     6  #> 53538 15828  3569   451    16     1  #>  #> $npoints_per_class #>     1     2     9  #> 61347  8159  3897  #>  #> $z_histogram #>   788   790   792   794   796   798   800   802   804   806   808   810   812  #>     1   163   265   470   596   694  1610  4955  5510 13833  9974  9865  8076  #>   814   816   818   820   822   824   826   828   830  #>  6643  4682  2958  1715   830   390   146    26     1  #>  #> $i_histogram #>   50   75  100  125  150  175  200  225  250  275  300  325  350  375  400  425  #>    8   51  168  422  485  677  697 1293 1453 1312 1337 1132 1145 1111 1003  962  #>  450  475  500  525  550  575  600  625  650  675  700  725  750  775  800  825  #> 1223 1286 1328 1198 1129 1108 1345 1293 1205 1218 1348 1399 1249 1212 1363 1327  #>  850  875  900  925  950  975 1000 1025 1050 1075 1100 1125 1150 1175 1200 1225  #> 1395 1469 1394 1419 1426 1571 1627 1564 1646 1734 1772 1827 1695 1709 1600 1411  #> 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525 1550 1575 1600 1625  #> 1339 1192 1245 1409 1848 1887 1939 1428  966  544  250  132   91   58   54   52  #> 1650 1675 1700 1725 1750 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000 2025  #>   46   40   30   29   14   14    5    6    5    7    4    6    6    1    4    1  #> 2050 2075 2100 2125 2150 2175 2200 2225 2250 2275 2300 2325 2350 2375 2400 2425  #>    0    1    0    0    0    0    2    1    0    0    0    0    0    0    0    0  #> 2450  #>    1  #>"},{"path":"/reference/temporary_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporary files — temporary_files","title":"Temporary files — temporary_files","text":"Convenient functions create temporary file given extension.","code":""},{"path":"/reference/temporary_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporary files — temporary_files","text":"","code":"temptif()  tempgpkg()  tempshp()  templas()  templaz()"},{"path":"/reference/temporary_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporary files — temporary_files","text":"string. Path temporary file.","code":""},{"path":"/reference/temporary_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporary files — temporary_files","text":"","code":"tempshp() #> [1] \"/tmp/RtmpnYzbWe/file1fb938c74bb9.shp\" templaz() #> [1] \"/tmp/RtmpnYzbWe/file1fb972b578ec.laz\""},{"path":"/reference/tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools inherited from base R — tools","title":"Tools inherited from base R — tools","text":"Tools inherited base R","code":""},{"path":"/reference/tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools inherited from base R — tools","text":"","code":"# S3 method for LASRalgorithm print(x, ...)  # S3 method for LASRpipeline print(x, ...)  # S3 method for LASRpipeline +(e1, e2)  # S3 method for LASRpipeline c(...)"},{"path":"/reference/tools.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools inherited from base R — tools","text":"x, e1, e2 lasR objects ... lasR objects. equivalent +","code":""},{"path":"/reference/tools.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools inherited from base R — tools","text":"","code":"algo1 <- rasterize(1, \"max\") algo2 <- rasterize(4, \"min\") print(algo1) #>  ----------- #> rasterize (uid:8atPIr) #>   res : 1  #>   window : 1  #>   method : max  #>   filter :   #>   output : /tmp/RtmpnYzbWe/file1fb95c0e85e3.tif  #> ----------- pipeline <- algo1 + algo2 print(pipeline) #>  ----------- #> rasterize (uid:8atPIr) #>   res : 1  #>   window : 1  #>   method : max  #>   filter :   #>   output : /tmp/RtmpnYzbWe/file1fb95c0e85e3.tif  #> ----------- #> rasterize (uid:MnPPoH) #>   res : 4  #>   window : 4  #>   method : min  #>   filter :   #>   output : /tmp/RtmpnYzbWe/file1fb97ececab8.tif  #> -----------"},{"path":"/reference/transform_with.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a point cloud using another stage — transform_with","title":"Transform a point cloud using another stage — transform_with","text":"stage uses another stage produced Delaunay triangulation raster performs operation modify point cloud. can typically used build normalization stage stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/transform_with.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a point cloud using another stage — transform_with","text":"","code":"transform_with(stage, operator = \"-\", store_in_attribute = \"\")"},{"path":"/reference/transform_with.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a point cloud using another stage — transform_with","text":"stage LASRpipeline. stage produces triangulation raster. operator string. '-' '+' supported. store_in_attribute numeric. Use extra bytes attribute store result.","code":""},{"path":[]},{"path":"/reference/transform_with.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a point cloud using another stage — transform_with","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\")  # There is a normalize pipeline in lasR but let's create one almost equivalent mesh  <- triangulate(filter = keep_ground()) trans <- transform_with(mesh) pipeline <- mesh + trans + write_las() ans <- exec(pipeline, on = f)"},{"path":"/reference/triangulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Delaunay triangulation — triangulate","title":"Delaunay triangulation — triangulate","text":"Delaunay triangulation. Can used build DTM, CHM, normalize point cloud, application. stage typically used intermediate process without output file. stage modify point cloud.","code":""},{"path":"/reference/triangulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delaunay triangulation — triangulate","text":"","code":"triangulate(max_edge = 0, filter = \"\", ofile = \"\", use_attribute = \"Z\")"},{"path":"/reference/triangulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delaunay triangulation — triangulate","text":"max_edge numeric. Maximum edge length triangle Delaunay triangulation. triangle edge length greater value, removed. max_edge = 0, trimming done (see examples). filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. default triangulation performed coordinate Z. Can also name extra bytes attribute 'HAG' exists. Can also 'Intensity'.","code":""},{"path":"/reference/triangulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delaunay triangulation — triangulate","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri1 <- triangulate(25, filter = keep_ground(), ofile = tempgpkg()) filter <- \"-keep_last -keep_random_fraction 0.1\" tri2 <- triangulate(filter = filter, ofile = tempgpkg()) pipeline <- read + tri1 + tri2 ans <- exec(pipeline, on = f) #plot(ans[[1]]) #plot(ans[[2]])"},{"path":"/reference/write_las.html","id":null,"dir":"Reference","previous_headings":"","what":"Write LAS or LAZ files — write_las","title":"Write LAS or LAZ files — write_las","text":"Write LAS LAZ file step pipeline (typically end). Unlike stages, output written single large file multiple tiled files corresponding original collection files.","code":""},{"path":"/reference/write_las.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write LAS or LAZ files — write_las","text":"","code":"write_las(   ofile = paste0(tempdir(), \"/*.las\"),   filter = \"\",   keep_buffer = FALSE )"},{"path":"/reference/write_las.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write LAS or LAZ files — write_las","text":"ofile character. Output file names. string must contain wildcard * wildcard can replaced name original tile preserve tiling pattern. wildcard omitted, everything written single file. may desired behavior circumstances, e.g., merge files. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given algorithm filter applied, points meet criteria processes. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. keep_buffer bool. buffer removed write file can preserved.","code":""},{"path":"/reference/write_las.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write LAS or LAZ files — write_las","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri  <- triangulate(filter = keep_ground()) normalize <- tri + transform_with(tri) pipeline <- read + normalize + write_las(paste0(tempdir(), \"/*_norm.las\")) exec(pipeline, on = f) #> [1] \"/tmp/RtmpnYzbWe/Topography_norm.las\""},{"path":"/reference/write_vpc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a Virtual Point Cloud — write_vpc","title":"Write a Virtual Point Cloud — write_vpc","text":"Borrowing concept virtual rasters GDAL, VPC file format references point cloud files virtual point cloud (VPC)","code":""},{"path":"/reference/write_vpc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"write_vpc(ofile)"},{"path":"/reference/write_vpc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a Virtual Point Cloud — write_vpc","text":"ofile character. file path extension .vpc write virtual point cloud file","code":""},{"path":"/reference/write_vpc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Write a Virtual Point Cloud — write_vpc","text":"https://www.lutraconsulting.co.uk/blog/2023/06/08/virtual-point-clouds/https://github.com/PDAL/wrench/blob/main/vpc-spec.md","code":""},{"path":"/reference/write_vpc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"if (FALSE) { pipeline = write_vpc(\"folder/dataset.vpc\") exec(pipeline, on = \"folder\") }"},{"path":"/news/index.html","id":"lasr-036","dir":"Changelog","previous_headings":"","what":"lasR 0.3.6","title":"lasR 0.3.6","text":"Fix: #18 strongly improving arithmetic accuracy point_in_triangle.","code":""},{"path":"/news/index.html","id":"lasr-035","dir":"Changelog","previous_headings":"","what":"lasR 0.3.5","title":"lasR 0.3.5","text":"Fix: #17 transform_with can used pit_fill","code":""},{"path":"/news/index.html","id":"lasr-034","dir":"Changelog","previous_headings":"","what":"lasR 0.3.4","title":"lasR 0.3.4","text":"Fix: #15 pit_fill producing corrupted output Fix: pit_fill respecting parameters given user Fix: pit_fill combination rasterize(\"max\") working properly","code":""},{"path":"/news/index.html","id":"lasr-033","dir":"Changelog","previous_headings":"","what":"lasR 0.3.3","title":"lasR 0.3.3","text":"Fix: #12 write lax buffered chunk Fix: #13 processing chunk buffered","code":""},{"path":"/news/index.html","id":"lasr-032","dir":"Changelog","previous_headings":"","what":"lasR 0.3.2","title":"lasR 0.3.2","text":"Fix: CRS working Windows Fix: library(lasR) transparently checks latest version Windows.","code":""},{"path":"/news/index.html","id":"lasr-031","dir":"Changelog","previous_headings":"","what":"lasR 0.3.1","title":"lasR 0.3.1","text":"Fix: bugs making spatial query multiple files multiple spatial indexing systems (e.g. lax+nothing, lax+copc)","code":""},{"path":"/news/index.html","id":"lasr-030","dir":"Changelog","previous_headings":"","what":"lasR 0.3.0","title":"lasR 0.3.0","text":"Change: processor() reader() deprecated replaced exec() reader_las(). intends provide consistent natural way separate pipeline. .e stages global processing options .e. buffer, chunking, progress bar. example following now respects LAScatalog processing options possible previous syntax. New: processor now able process chunk like lidR New: stage delete_points() remove points pipeline. New: now possible write following: New: possible omit reader stage. automatically adds default reader New: triangulation 4x faster uses half memory. Fix: summarize(), rasterize() write_las() longer process withheld points streaming mode.","code":"ctg = lidR::readLAScatalog() pipeline = reader_las() + rasterize(...) exec(pipeline, on = ctg) pipeline = reader_las() + rasterize(...) exec(pipeline, on = file, chunk = 500) dtm = dtm() pipeline <- read + dtm + transform_with(dtm[[2]]) pipeline = rasterize(...) exec(pipeline, on = ctg)"},{"path":"/news/index.html","id":"lasr-021-2024-03-05","dir":"Changelog","previous_headings":"","what":"lasR 0.2.1 (2024-03-05)","title":"lasR 0.2.1 (2024-03-05)","text":"Fix: callback() properly handles errors injected function New: handy functions tempxyz() generate temp files extension .xyz. New: rasterize() now parallelized internal metrics including buffered area based approach New: rasterize() gained progress bar internal metrics.","code":""},{"path":"/news/index.html","id":"lasr-020-2024-03-01","dir":"Changelog","previous_headings":"","what":"lasR 0.2.0 (2024-03-01)","title":"lasR 0.2.0 (2024-03-01)","text":"New: rasterize() gains ability perform multi-resolution buffered rasterization. See documentation. New: rasterize() gains numerous native metrics zmax, zmean, zmedian, imax, imean . New: internal engine gains ability skip processing files collection use files load buffer. feature works LAScatalog lidR respecting processed attribute used lidR Fix: loading package offline created bug R longer handles errors.","code":""},{"path":"/news/index.html","id":"lasr-012-2024-02-10","dir":"Changelog","previous_headings":"","what":"lasR 0.1.2 (2024-02-10)","title":"lasR 0.1.2 (2024-02-10)","text":"New: progress bar reading header files (LAScatalog) can enabled progress = TRUE Fix: progress bar starts appear earlier .e. 0%. pipeline affects feeling progress.","code":""},{"path":"/news/index.html","id":"lasr-011-2024-02-08","dir":"Changelog","previous_headings":"","what":"lasR 0.1.1 (2024-02-08)","title":"lasR 0.1.1 (2024-02-08)","text":"Doc: Corrected documentation argument ncores processor(), incorrectly mentioned supported. New: Added new functions ncores() half_cores(). Fix: Corrected reader progress bar display reading las file filter buffer. Fix: Fixed overall progress bar, delayed one file showing incorrect progress.","code":""}]
